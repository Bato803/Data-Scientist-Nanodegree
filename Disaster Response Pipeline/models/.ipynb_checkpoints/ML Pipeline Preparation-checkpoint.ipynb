{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Bato/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/Bato/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/Bato/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# General libraries\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# import NLP libs\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet') # download for lemmatization\n",
    "\n",
    "# import ML libs\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table clean_all not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql_table\u001b[0;34m(table_name, con, schema, index_col, coerce_float, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreflect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mviews\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0msqlalchemy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidRequestError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sqlalchemy/sql/schema.py\u001b[0m in \u001b[0;36mreflect\u001b[0;34m(self, bind, schema, views, only, extend_existing, autoload_replace, **dialect_kwargs)\u001b[0m\n\u001b[1;32m   3955\u001b[0m                         \u001b[0;34m'in %r%s: (%s)'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3956\u001b[0;31m                         (bind.engine, s, ', '.join(missing)))\n\u001b[0m\u001b[1;32m   3957\u001b[0m                 load = [name for name in only if extend_existing or\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: Could not reflect: requested table(s) not available in Engine(sqlite:///InsertDatabaseName.db): (clean_all)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-68d720f8e9ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load data from database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sqlite:///InsertDatabaseName.db'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clean_all'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql_table\u001b[0;34m(table_name, con, schema, index_col, coerce_float, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreflect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mviews\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0msqlalchemy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidRequestError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Table %s not found\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtable_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mpandas_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSQLDatabase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Table clean_all not found"
     ]
    }
   ],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///InsertDatabaseName.db')\n",
    "df = pd.read_sql_table('clean_all', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['message'].values\n",
    "Y = df.drop(['id', 'message', 'original', 'genre'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related-1</th>\n",
       "      <th>request-0</th>\n",
       "      <th>offer-0</th>\n",
       "      <th>aid_related-0</th>\n",
       "      <th>medical_help-0</th>\n",
       "      <th>medical_products-0</th>\n",
       "      <th>search_and_rescue-0</th>\n",
       "      <th>security-0</th>\n",
       "      <th>military-0</th>\n",
       "      <th>child_alone-0</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers-0</th>\n",
       "      <th>other_infrastructure-0</th>\n",
       "      <th>weather_related-0</th>\n",
       "      <th>floods-0</th>\n",
       "      <th>storm-0</th>\n",
       "      <th>fire-0</th>\n",
       "      <th>earthquake-0</th>\n",
       "      <th>cold-0</th>\n",
       "      <th>other_weather-0</th>\n",
       "      <th>direct_report-0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   related-1  request-0  offer-0  aid_related-0  medical_help-0  \\\n",
       "0          1          0        0              0               0   \n",
       "1          1          0        0              1               0   \n",
       "2          1          0        0              0               0   \n",
       "3          1          1        0              1               0   \n",
       "4          1          0        0              0               0   \n",
       "\n",
       "   medical_products-0  search_and_rescue-0  security-0  military-0  \\\n",
       "0                   0                    0           0           0   \n",
       "1                   0                    0           0           0   \n",
       "2                   0                    0           0           0   \n",
       "3                   1                    0           0           0   \n",
       "4                   0                    0           0           0   \n",
       "\n",
       "   child_alone-0       ...         aid_centers-0  other_infrastructure-0  \\\n",
       "0              0       ...                     0                       0   \n",
       "1              0       ...                     0                       0   \n",
       "2              0       ...                     0                       0   \n",
       "3              0       ...                     0                       0   \n",
       "4              0       ...                     0                       0   \n",
       "\n",
       "   weather_related-0  floods-0  storm-0  fire-0  earthquake-0  cold-0  \\\n",
       "0                  0         0        0       0             0       0   \n",
       "1                  1         0        1       0             0       0   \n",
       "2                  0         0        0       0             0       0   \n",
       "3                  0         0        0       0             0       0   \n",
       "4                  0         0        0       0             0       0   \n",
       "\n",
       "   other_weather-0  direct_report-0  \n",
       "0                0                0  \n",
       "1                0                0  \n",
       "2                0                0  \n",
       "3                0                0  \n",
       "4                0                0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['related-1', 'request-0', 'offer-0', 'aid_related-0', 'medical_help-0',\n",
       "       'medical_products-0', 'search_and_rescue-0', 'security-0', 'military-0',\n",
       "       'child_alone-0', 'water-0', 'food-0', 'shelter-0', 'clothing-0',\n",
       "       'money-0', 'missing_people-0', 'refugees-0', 'death-0', 'other_aid-0',\n",
       "       'infrastructure_related-0', 'transport-0', 'buildings-0',\n",
       "       'electricity-0', 'tools-0', 'hospitals-0', 'shops-0', 'aid_centers-0',\n",
       "       'other_infrastructure-0', 'weather_related-0', 'floods-0', 'storm-0',\n",
       "       'fire-0', 'earthquake-0', 'cold-0', 'other_weather-0',\n",
       "       'direct_report-0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@CNN: What to expect when Hurricane Sandy hits. http://t.co/4nGQT6cn‚àö√Ü @DogGoneBlog'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[12540]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://t.co/4nGQT6cn']\n"
     ]
    }
   ],
   "source": [
    "url_re = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "a = \"https://classroom.udacity.com/nanodegrees/nd025/parts/\"\n",
    "print(re.findall(url_re, X[12540]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # url re expression, credit: https://www.geeksforgeeks.org/python-check-url-string/\n",
    "    url_re = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    urls = re.findall(url_re, text)\n",
    "    \n",
    "    # Replace urls in text with a string. Make it easier for the model to learn the pattern. \n",
    "    for url in urls:\n",
    "        text.replace(url, 'url')\n",
    "    \n",
    "    # Normalize text\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    # Tokenize words. \n",
    "    words = nltk.tokenize.word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words. \n",
    "    words = [x for x in words if x not in stopwords.words('english')]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmed = [WordNetLemmatizer().lemmatize(w).strip() for w in words]\n",
    "    \n",
    "    return lemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "- You'll find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline():\n",
    "    pipeline = Pipeline([\n",
    "        ('vec', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier(class_weight='balanced')))\n",
    "    ])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "\n",
    "pipeline = build_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_...oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(y_true, y_pred):\n",
    "    cats = y_true.columns.values\n",
    "    y_true = y_true.values\n",
    "    print(\"{0:>30}\\t\\tPre\\tRecall\\tF1\".format(\"\"))\n",
    "    \n",
    "    pres, recalls, f1s = [], [], []\n",
    "    \n",
    "    for i, cat in enumerate(cats):\n",
    "        pre = precision_score(y_true[:, i], y_pred[:, i], average=\"weighted\")\n",
    "        recall = recall_score(y_true[:, i], y_pred[:, i], average=\"weighted\")\n",
    "        f1 = f1_score(y_true[:, i], y_pred[:, i], average=\"weighted\")\n",
    "        \n",
    "        pres.append(pre)\n",
    "        recalls.append(pre)\n",
    "        f1s.append(f1)\n",
    "        \n",
    "        print(\"{0:>30}\\t\\t{1:.3}\\t{2:.3}\\t{3:.3}\".format(cat, pre, recall, f1))\n",
    "    \n",
    "    print(\"{0:>30}\\t\\t{1:.3}\\t{2:.3}\\t{3:.3}\".format(\"Ave\", np.mean(pres),\n",
    "                                                     np.mean(recalls), np.mean(f1s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              \t\tPre\tRecall\tF1\n",
      "                     related-1\t\t0.796\t0.806\t0.798\n",
      "                     request-0\t\t0.878\t0.885\t0.872\n",
      "                       offer-0\t\t0.99\t0.995\t0.992\n",
      "                 aid_related-0\t\t0.743\t0.744\t0.74\n",
      "                medical_help-0\t\t0.902\t0.923\t0.897\n",
      "            medical_products-0\t\t0.938\t0.953\t0.936\n",
      "           search_and_rescue-0\t\t0.96\t0.973\t0.959\n",
      "                    security-0\t\t0.961\t0.98\t0.97\n",
      "                    military-0\t\t0.957\t0.967\t0.954\n",
      "                 child_alone-0\t\t1.0\t1.0\t1.0\n",
      "                       water-0\t\t0.949\t0.954\t0.947\n",
      "                        food-0\t\t0.922\t0.928\t0.92\n",
      "                     shelter-0\t\t0.925\t0.932\t0.915\n",
      "                    clothing-0\t\t0.981\t0.985\t0.978\n",
      "                       money-0\t\t0.972\t0.978\t0.968\n",
      "              missing_people-0\t\t0.984\t0.988\t0.983\n",
      "                    refugees-0\t\t0.948\t0.967\t0.952\n",
      "                       death-0\t\t0.952\t0.959\t0.945\n",
      "                   other_aid-0\t\t0.84\t0.873\t0.83\n",
      "      infrastructure_related-0\t\t0.908\t0.936\t0.905\n",
      "                   transport-0\t\t0.939\t0.953\t0.932\n",
      "                   buildings-0\t\t0.944\t0.953\t0.937\n",
      "                 electricity-0\t\t0.978\t0.982\t0.975\n",
      "                       tools-0\t\t0.991\t0.995\t0.993\n",
      "                   hospitals-0\t\t0.984\t0.989\t0.984\n",
      "                       shops-0\t\t0.99\t0.995\t0.992\n",
      "                 aid_centers-0\t\t0.977\t0.988\t0.982\n",
      "        other_infrastructure-0\t\t0.928\t0.956\t0.936\n",
      "             weather_related-0\t\t0.849\t0.853\t0.846\n",
      "                      floods-0\t\t0.927\t0.931\t0.914\n",
      "                       storm-0\t\t0.915\t0.925\t0.912\n",
      "                        fire-0\t\t0.991\t0.99\t0.986\n",
      "                  earthquake-0\t\t0.961\t0.962\t0.96\n",
      "                        cold-0\t\t0.982\t0.983\t0.976\n",
      "               other_weather-0\t\t0.925\t0.948\t0.924\n",
      "               direct_report-0\t\t0.836\t0.851\t0.832\n",
      "                           Ave\t\t0.934\t0.934\t0.932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] clf__estimator__n_estimators=10 .................................\n",
      "[CV]  clf__estimator__n_estimators=10, score=0.23850057292519233, total= 2.2min\n",
      "[CV] clf__estimator__n_estimators=10 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=10, score=0.22917007693566868, total= 2.2min\n",
      "[CV] clf__estimator__n_estimators=10 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  6.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=10, score=0.2311722331368697, total= 2.2min\n",
      "[CV] clf__estimator__n_estimators=50 .................................\n",
      "[CV]  clf__estimator__n_estimators=50, score=0.2511049271566541, total= 4.5min\n",
      "[CV] clf__estimator__n_estimators=50 .................................\n",
      "[CV]  clf__estimator__n_estimators=50, score=0.24177443116713046, total= 4.5min\n",
      "[CV] clf__estimator__n_estimators=50 .................................\n",
      "[CV]  clf__estimator__n_estimators=50, score=0.24459724950884087, total= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 26.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_...oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "           n_jobs=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'clf__estimator__n_estimators': [10, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "        'clf__estimator__n_estimators':[10, 50]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(estimator=pipeline, param_grid=parameters, verbose=3)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              \t\tPre\tRecall\tF1\n",
      "                     related-1\t\t0.796\t0.806\t0.798\n",
      "                     request-0\t\t0.878\t0.885\t0.872\n",
      "                       offer-0\t\t0.99\t0.995\t0.992\n",
      "                 aid_related-0\t\t0.743\t0.744\t0.74\n",
      "                medical_help-0\t\t0.902\t0.923\t0.897\n",
      "            medical_products-0\t\t0.938\t0.953\t0.936\n",
      "           search_and_rescue-0\t\t0.96\t0.973\t0.959\n",
      "                    security-0\t\t0.961\t0.98\t0.97\n",
      "                    military-0\t\t0.957\t0.967\t0.954\n",
      "                 child_alone-0\t\t1.0\t1.0\t1.0\n",
      "                       water-0\t\t0.949\t0.954\t0.947\n",
      "                        food-0\t\t0.922\t0.928\t0.92\n",
      "                     shelter-0\t\t0.925\t0.932\t0.915\n",
      "                    clothing-0\t\t0.981\t0.985\t0.978\n",
      "                       money-0\t\t0.972\t0.978\t0.968\n",
      "              missing_people-0\t\t0.984\t0.988\t0.983\n",
      "                    refugees-0\t\t0.948\t0.967\t0.952\n",
      "                       death-0\t\t0.952\t0.959\t0.945\n",
      "                   other_aid-0\t\t0.84\t0.873\t0.83\n",
      "      infrastructure_related-0\t\t0.908\t0.936\t0.905\n",
      "                   transport-0\t\t0.939\t0.953\t0.932\n",
      "                   buildings-0\t\t0.944\t0.953\t0.937\n",
      "                 electricity-0\t\t0.978\t0.982\t0.975\n",
      "                       tools-0\t\t0.991\t0.995\t0.993\n",
      "                   hospitals-0\t\t0.984\t0.989\t0.984\n",
      "                       shops-0\t\t0.99\t0.995\t0.992\n",
      "                 aid_centers-0\t\t0.977\t0.988\t0.982\n",
      "        other_infrastructure-0\t\t0.928\t0.956\t0.936\n",
      "             weather_related-0\t\t0.849\t0.853\t0.846\n",
      "                      floods-0\t\t0.927\t0.931\t0.914\n",
      "                       storm-0\t\t0.915\t0.925\t0.912\n",
      "                        fire-0\t\t0.991\t0.99\t0.986\n",
      "                  earthquake-0\t\t0.961\t0.962\t0.96\n",
      "                        cold-0\t\t0.982\t0.983\t0.976\n",
      "               other_weather-0\t\t0.925\t0.948\t0.924\n",
      "               direct_report-0\t\t0.836\t0.851\t0.832\n",
      "                           Ave\t\t0.934\t0.934\t0.932\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred_2 = cv.predict(X_test)\n",
    "print(report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_gb = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(\n",
    "        AdaBoostClassifier(n_estimators=100)\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ator=None,\n",
       "          learning_rate=1.0, n_estimators=100, random_state=None),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_gb.fit(X_train, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gb = pipeline_gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              \t\tPre\tRecall\tF1\n",
      "                     related-1\t\t0.754\t0.783\t0.741\n",
      "                     request-0\t\t0.882\t0.889\t0.881\n",
      "                       offer-0\t\t0.99\t0.993\t0.992\n",
      "                 aid_related-0\t\t0.767\t0.768\t0.764\n",
      "                medical_help-0\t\t0.908\t0.924\t0.91\n",
      "            medical_products-0\t\t0.945\t0.954\t0.948\n",
      "           search_and_rescue-0\t\t0.966\t0.973\t0.968\n",
      "                    security-0\t\t0.967\t0.978\t0.971\n",
      "                    military-0\t\t0.964\t0.97\t0.966\n",
      "                 child_alone-0\t\t1.0\t1.0\t1.0\n",
      "                       water-0\t\t0.958\t0.96\t0.959\n",
      "                        food-0\t\t0.94\t0.943\t0.941\n",
      "                     shelter-0\t\t0.937\t0.942\t0.938\n",
      "                    clothing-0\t\t0.985\t0.987\t0.986\n",
      "                       money-0\t\t0.975\t0.979\t0.976\n",
      "              missing_people-0\t\t0.986\t0.989\t0.986\n",
      "                    refugees-0\t\t0.96\t0.967\t0.962\n",
      "                       death-0\t\t0.959\t0.964\t0.961\n",
      "                   other_aid-0\t\t0.835\t0.869\t0.84\n",
      "      infrastructure_related-0\t\t0.903\t0.928\t0.912\n",
      "                   transport-0\t\t0.945\t0.956\t0.945\n",
      "                   buildings-0\t\t0.95\t0.957\t0.952\n",
      "                 electricity-0\t\t0.978\t0.981\t0.98\n",
      "                       tools-0\t\t0.991\t0.994\t0.992\n",
      "                   hospitals-0\t\t0.983\t0.987\t0.985\n",
      "                       shops-0\t\t0.99\t0.994\t0.992\n",
      "                 aid_centers-0\t\t0.98\t0.986\t0.983\n",
      "        other_infrastructure-0\t\t0.932\t0.95\t0.939\n",
      "             weather_related-0\t\t0.88\t0.882\t0.879\n",
      "                      floods-0\t\t0.949\t0.953\t0.948\n",
      "                       storm-0\t\t0.932\t0.938\t0.933\n",
      "                        fire-0\t\t0.988\t0.99\t0.989\n",
      "                  earthquake-0\t\t0.969\t0.97\t0.969\n",
      "                        cold-0\t\t0.981\t0.984\t0.982\n",
      "               other_weather-0\t\t0.93\t0.946\t0.935\n",
      "               direct_report-0\t\t0.839\t0.852\t0.841\n",
      "                           Ave\t\t0.939\t0.939\t0.94\n"
     ]
    }
   ],
   "source": [
    "report(y_test, y_pred_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pipeline_gb, open(\"Adaboost.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
